{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74efb76a",
   "metadata": {},
   "source": [
    "### Combine frames into a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7085f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929bf417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames path is:  /home/aevas/Desktop/annotations for YBS/uav0000072_04488_v\n"
     ]
    }
   ],
   "source": [
    "#setting frame path and output path\n",
    "frames_path = '/home/aevas/Desktop/annotations for YBS/uav0000072_04488_v'\n",
    "output_path = '/home/aevas/Desktop/annotations for YBS/output'\n",
    "\n",
    "print(\"frames path is: \", frames_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d7c72fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textfile_path is:  /home/aevas/Desktop/annotations for YBS/uav0000072_04488_v.txt\n"
     ]
    }
   ],
   "source": [
    "#setting path to annotation file\n",
    "\n",
    "textfile_path = frames_path + \".txt\"\n",
    "print(\"textfile_path is: \", textfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce1710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#getting list of images and preparing list of image names\n",
    "images = [img for img in os.listdir(frames_path)\n",
    "          if img.endswith(\".jpg\") or\n",
    "             img.endswith(\".jpeg\") or\n",
    "             img.endswith(\"png\")]\n",
    "\n",
    "frame = cv2.imread(os.path.join(frames_path, images[0]))\n",
    "height, width, layers = frame.shape   #getting dimensions of images \n",
    "\n",
    "images = sorted(images) #sorting because the files will not be read in proper order normally\n",
    "#print(images) #debug, you should see that the images are listed out in the correct order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23109c92",
   "metadata": {},
   "source": [
    "### to process annotations\n",
    "\n",
    "classes\n",
    "names:\n",
    "-  0: pedestrian\n",
    "-  1: people\n",
    "-  2: bicycle\n",
    "-  3: car\n",
    "-  4: van\n",
    "-  5: truck\n",
    "-  6: tricycle\n",
    "-  7: awning-tricycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6049a3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_path_name is:  /home/aevas/Desktop/annotations for YBS/output/uav0000072_04488_v_fps15_wbboxes.mp4\n"
     ]
    }
   ],
   "source": [
    "#set up video properties\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # deciding codec and video format \n",
    "fps = 15\n",
    "\n",
    "video_wbbox_path_name = output_path + '/' + frames_path.split(\"/\")[-1] +  '_fps' + str(fps) + \"_wbboxes\" + \".mp4\"\n",
    "print(\"video_path_name is: \", video_wbbox_path_name)\n",
    "\n",
    "video_wbbox = cv2.VideoWriter(video_wbbox_path_name, fourcc, fps, (width, height)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e3a04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process annotations in text file\n",
    "\n",
    "with open(textfile_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    #print(lines)\n",
    "\n",
    "annotations = []\n",
    "    \n",
    "for line in lines:\n",
    "    #print(line)\n",
    "    ints = [int(x) for x in line.split(\",\")]\n",
    "    frame_no, ID, bbox_x, bbox_y, bbox_w, bbox_h, score, obj_class , trunc , occlu = ints\n",
    "    ID = str(ID) # ID needs to be string, since cv2 putText needs a string\n",
    "    annotations.append((frame_no, ID, bbox_x, bbox_y, bbox_w, bbox_h, score, obj_class , trunc , occlu))\n",
    "\n",
    "\n",
    "#print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e97259a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000001.jpg\n",
      "0000002.jpg\n",
      "0000003.jpg\n",
      "0000004.jpg\n",
      "0000005.jpg\n",
      "0000006.jpg\n",
      "0000007.jpg\n",
      "0000008.jpg\n",
      "0000009.jpg\n",
      "0000010.jpg\n",
      "0000011.jpg\n",
      "0000012.jpg\n",
      "0000013.jpg\n",
      "0000014.jpg\n",
      "0000015.jpg\n",
      "0000016.jpg\n",
      "0000017.jpg\n",
      "0000018.jpg\n",
      "0000019.jpg\n",
      "0000020.jpg\n",
      "0000021.jpg\n",
      "0000022.jpg\n",
      "0000023.jpg\n",
      "0000024.jpg\n",
      "0000025.jpg\n",
      "0000026.jpg\n",
      "0000027.jpg\n",
      "0000028.jpg\n",
      "0000029.jpg\n",
      "0000030.jpg\n",
      "0000031.jpg\n",
      "0000032.jpg\n",
      "0000033.jpg\n",
      "0000034.jpg\n",
      "0000035.jpg\n",
      "0000036.jpg\n",
      "0000037.jpg\n",
      "0000038.jpg\n",
      "0000039.jpg\n",
      "0000040.jpg\n",
      "0000041.jpg\n",
      "0000042.jpg\n",
      "0000043.jpg\n",
      "0000044.jpg\n",
      "0000045.jpg\n",
      "0000046.jpg\n",
      "0000047.jpg\n",
      "0000048.jpg\n",
      "0000049.jpg\n",
      "0000050.jpg\n",
      "0000051.jpg\n",
      "0000052.jpg\n",
      "0000053.jpg\n",
      "0000054.jpg\n",
      "0000055.jpg\n",
      "0000056.jpg\n",
      "0000057.jpg\n",
      "0000058.jpg\n",
      "0000059.jpg\n",
      "0000060.jpg\n",
      "0000061.jpg\n",
      "0000062.jpg\n",
      "0000063.jpg\n",
      "0000064.jpg\n",
      "0000065.jpg\n",
      "0000066.jpg\n",
      "0000067.jpg\n",
      "0000068.jpg\n",
      "0000069.jpg\n",
      "0000070.jpg\n",
      "0000071.jpg\n",
      "0000072.jpg\n",
      "0000073.jpg\n",
      "0000074.jpg\n",
      "0000075.jpg\n",
      "0000076.jpg\n",
      "0000077.jpg\n",
      "0000078.jpg\n",
      "0000079.jpg\n",
      "0000080.jpg\n",
      "0000081.jpg\n",
      "0000082.jpg\n",
      "0000083.jpg\n",
      "0000084.jpg\n",
      "0000085.jpg\n",
      "video done writing\n"
     ]
    }
   ],
   "source": [
    "for count, image in enumerate(images): \n",
    "    print(image)\n",
    "    image = cv2.imread(os.path.join(frames_path, image))\n",
    "    cv2.putText(image, str(count), (30,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2) #adds current frame count to top left\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        if count == annotation[0]:\n",
    "            image = cv2.rectangle(image, (annotation[2], annotation[3]), (annotation[2] + annotation[4], annotation[3] + annotation[5]), (0,255,255), 2)\n",
    "            image = cv2.putText(image, annotation[1], (annotation[2], annotation[3]), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,255,255), 1)\n",
    "    video_wbbox.write(image)\n",
    "\n",
    "\n",
    "# Deallocating memories taken for window creation\n",
    "print('video done writing') \n",
    "cv2.destroyAllWindows()\n",
    "video_wbbox.release()  # releasing the video generated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy39",
   "language": "python",
   "name": "newpy39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
